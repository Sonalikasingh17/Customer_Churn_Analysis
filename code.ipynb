{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc314a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "accc2e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Task 02/merged_raw_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee6e43c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def clean_and_process_data(df):\n",
    "    \"\"\"\n",
    "    Cleans and processes merged raw data for machine learning.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Raw merged data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned and processed data ready for modeling.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # Drop duplicate rows\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # Handle missing values (numerical and categorical separately)\n",
    "    num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    cat_cols = df.select_dtypes(include=['object', 'category', 'bool']).columns\n",
    "\n",
    "    imputer_num = SimpleImputer(strategy='mean')\n",
    "    imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "    df[num_cols] = imputer_num.fit_transform(df[num_cols])\n",
    "    df[cat_cols] = imputer_cat.fit_transform(df[cat_cols])\n",
    "\n",
    "    # Encode categorical features\n",
    "    encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "    encoded_cat = encoder.fit_transform(df[cat_cols])\n",
    "    encoded_cat_df = pd.DataFrame(encoded_cat, columns=encoder.get_feature_names_out(cat_cols), index=df.index)\n",
    "\n",
    "    df = df.drop(columns=cat_cols)\n",
    "    df = pd.concat([df, encoded_cat_df], axis=1)\n",
    "\n",
    "    # Feature scaling for numerical features\n",
    "    scaler = StandardScaler()\n",
    "    df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c747c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>IncomeLevel</th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>TransactionDate</th>\n",
       "      <th>AmountSpent</th>\n",
       "      <th>ProductCategory</th>\n",
       "      <th>InteractionID</th>\n",
       "      <th>InteractionDate</th>\n",
       "      <th>InteractionType</th>\n",
       "      <th>ResolutionStatus</th>\n",
       "      <th>LastLoginDate</th>\n",
       "      <th>LoginFrequency</th>\n",
       "      <th>ServiceUsage</th>\n",
       "      <th>ChurnStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>M</td>\n",
       "      <td>Single</td>\n",
       "      <td>Low</td>\n",
       "      <td>7194</td>\n",
       "      <td>2022-03-27</td>\n",
       "      <td>416.50</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>6363.0</td>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>Inquiry</td>\n",
       "      <td>Resolved</td>\n",
       "      <td>2023-10-21</td>\n",
       "      <td>34</td>\n",
       "      <td>Mobile App</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>M</td>\n",
       "      <td>Married</td>\n",
       "      <td>Low</td>\n",
       "      <td>7250</td>\n",
       "      <td>2022-08-08</td>\n",
       "      <td>54.96</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>2022-03-17</td>\n",
       "      <td>Inquiry</td>\n",
       "      <td>Resolved</td>\n",
       "      <td>2023-12-05</td>\n",
       "      <td>5</td>\n",
       "      <td>Website</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>M</td>\n",
       "      <td>Married</td>\n",
       "      <td>Low</td>\n",
       "      <td>9660</td>\n",
       "      <td>2022-07-25</td>\n",
       "      <td>197.50</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>2022-03-17</td>\n",
       "      <td>Inquiry</td>\n",
       "      <td>Resolved</td>\n",
       "      <td>2023-12-05</td>\n",
       "      <td>5</td>\n",
       "      <td>Website</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>M</td>\n",
       "      <td>Married</td>\n",
       "      <td>Low</td>\n",
       "      <td>2998</td>\n",
       "      <td>2022-01-25</td>\n",
       "      <td>101.31</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>2022-03-17</td>\n",
       "      <td>Inquiry</td>\n",
       "      <td>Resolved</td>\n",
       "      <td>2023-12-05</td>\n",
       "      <td>5</td>\n",
       "      <td>Website</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>M</td>\n",
       "      <td>Married</td>\n",
       "      <td>Low</td>\n",
       "      <td>1228</td>\n",
       "      <td>2022-07-24</td>\n",
       "      <td>397.37</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>2022-03-17</td>\n",
       "      <td>Inquiry</td>\n",
       "      <td>Resolved</td>\n",
       "      <td>2023-12-05</td>\n",
       "      <td>5</td>\n",
       "      <td>Website</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6807</th>\n",
       "      <td>1000</td>\n",
       "      <td>34</td>\n",
       "      <td>M</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Low</td>\n",
       "      <td>2724</td>\n",
       "      <td>2022-09-08</td>\n",
       "      <td>232.06</td>\n",
       "      <td>Groceries</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-13</td>\n",
       "      <td>22</td>\n",
       "      <td>Mobile App</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6808</th>\n",
       "      <td>1000</td>\n",
       "      <td>34</td>\n",
       "      <td>M</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Low</td>\n",
       "      <td>2917</td>\n",
       "      <td>2022-12-13</td>\n",
       "      <td>324.98</td>\n",
       "      <td>Books</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-13</td>\n",
       "      <td>22</td>\n",
       "      <td>Mobile App</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6809</th>\n",
       "      <td>1000</td>\n",
       "      <td>34</td>\n",
       "      <td>M</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Low</td>\n",
       "      <td>2979</td>\n",
       "      <td>2022-06-15</td>\n",
       "      <td>375.34</td>\n",
       "      <td>Groceries</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-13</td>\n",
       "      <td>22</td>\n",
       "      <td>Mobile App</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6810</th>\n",
       "      <td>1000</td>\n",
       "      <td>34</td>\n",
       "      <td>M</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Low</td>\n",
       "      <td>8594</td>\n",
       "      <td>2022-04-08</td>\n",
       "      <td>166.73</td>\n",
       "      <td>Books</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-13</td>\n",
       "      <td>22</td>\n",
       "      <td>Mobile App</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6811</th>\n",
       "      <td>1000</td>\n",
       "      <td>34</td>\n",
       "      <td>M</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Low</td>\n",
       "      <td>5529</td>\n",
       "      <td>2022-11-23</td>\n",
       "      <td>93.73</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-13</td>\n",
       "      <td>22</td>\n",
       "      <td>Mobile App</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6812 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CustomerID  Age Gender MaritalStatus IncomeLevel  TransactionID  \\\n",
       "0              1   62      M        Single         Low           7194   \n",
       "1              2   65      M       Married         Low           7250   \n",
       "2              2   65      M       Married         Low           9660   \n",
       "3              2   65      M       Married         Low           2998   \n",
       "4              2   65      M       Married         Low           1228   \n",
       "...          ...  ...    ...           ...         ...            ...   \n",
       "6807        1000   34      M       Widowed         Low           2724   \n",
       "6808        1000   34      M       Widowed         Low           2917   \n",
       "6809        1000   34      M       Widowed         Low           2979   \n",
       "6810        1000   34      M       Widowed         Low           8594   \n",
       "6811        1000   34      M       Widowed         Low           5529   \n",
       "\n",
       "     TransactionDate  AmountSpent ProductCategory  InteractionID  \\\n",
       "0         2022-03-27       416.50     Electronics         6363.0   \n",
       "1         2022-08-08        54.96        Clothing         3329.0   \n",
       "2         2022-07-25       197.50     Electronics         3329.0   \n",
       "3         2022-01-25       101.31       Furniture         3329.0   \n",
       "4         2022-07-24       397.37        Clothing         3329.0   \n",
       "...              ...          ...             ...            ...   \n",
       "6807      2022-09-08       232.06       Groceries            NaN   \n",
       "6808      2022-12-13       324.98           Books            NaN   \n",
       "6809      2022-06-15       375.34       Groceries            NaN   \n",
       "6810      2022-04-08       166.73           Books            NaN   \n",
       "6811      2022-11-23        93.73       Furniture            NaN   \n",
       "\n",
       "     InteractionDate InteractionType ResolutionStatus LastLoginDate  \\\n",
       "0         2022-03-31         Inquiry         Resolved    2023-10-21   \n",
       "1         2022-03-17         Inquiry         Resolved    2023-12-05   \n",
       "2         2022-03-17         Inquiry         Resolved    2023-12-05   \n",
       "3         2022-03-17         Inquiry         Resolved    2023-12-05   \n",
       "4         2022-03-17         Inquiry         Resolved    2023-12-05   \n",
       "...              ...             ...              ...           ...   \n",
       "6807             NaN             NaN              NaN    2023-08-13   \n",
       "6808             NaN             NaN              NaN    2023-08-13   \n",
       "6809             NaN             NaN              NaN    2023-08-13   \n",
       "6810             NaN             NaN              NaN    2023-08-13   \n",
       "6811             NaN             NaN              NaN    2023-08-13   \n",
       "\n",
       "      LoginFrequency ServiceUsage  ChurnStatus  \n",
       "0                 34   Mobile App            0  \n",
       "1                  5      Website            1  \n",
       "2                  5      Website            1  \n",
       "3                  5      Website            1  \n",
       "4                  5      Website            1  \n",
       "...              ...          ...          ...  \n",
       "6807              22   Mobile App            0  \n",
       "6808              22   Mobile App            0  \n",
       "6809              22   Mobile App            0  \n",
       "6810              22   Mobile App            0  \n",
       "6811              22   Mobile App            0  \n",
       "\n",
       "[6812 rows x 17 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33f66bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# Step 1: Load and inspect data\n",
    "df1= pd.read_csv('Task 02/merged_raw_dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2d42fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>IncomeLevel</th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>TransactionDate</th>\n",
       "      <th>AmountSpent</th>\n",
       "      <th>ProductCategory</th>\n",
       "      <th>InteractionID</th>\n",
       "      <th>InteractionDate</th>\n",
       "      <th>InteractionType</th>\n",
       "      <th>ResolutionStatus</th>\n",
       "      <th>LastLoginDate</th>\n",
       "      <th>LoginFrequency</th>\n",
       "      <th>ServiceUsage</th>\n",
       "      <th>ChurnStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>M</td>\n",
       "      <td>Single</td>\n",
       "      <td>Low</td>\n",
       "      <td>7194</td>\n",
       "      <td>2022-03-27</td>\n",
       "      <td>416.50</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>6363.0</td>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>Inquiry</td>\n",
       "      <td>Resolved</td>\n",
       "      <td>2023-10-21</td>\n",
       "      <td>34</td>\n",
       "      <td>Mobile App</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>M</td>\n",
       "      <td>Married</td>\n",
       "      <td>Low</td>\n",
       "      <td>7250</td>\n",
       "      <td>2022-08-08</td>\n",
       "      <td>54.96</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>2022-03-17</td>\n",
       "      <td>Inquiry</td>\n",
       "      <td>Resolved</td>\n",
       "      <td>2023-12-05</td>\n",
       "      <td>5</td>\n",
       "      <td>Website</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>M</td>\n",
       "      <td>Married</td>\n",
       "      <td>Low</td>\n",
       "      <td>9660</td>\n",
       "      <td>2022-07-25</td>\n",
       "      <td>197.50</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>2022-03-17</td>\n",
       "      <td>Inquiry</td>\n",
       "      <td>Resolved</td>\n",
       "      <td>2023-12-05</td>\n",
       "      <td>5</td>\n",
       "      <td>Website</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>M</td>\n",
       "      <td>Married</td>\n",
       "      <td>Low</td>\n",
       "      <td>2998</td>\n",
       "      <td>2022-01-25</td>\n",
       "      <td>101.31</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>2022-03-17</td>\n",
       "      <td>Inquiry</td>\n",
       "      <td>Resolved</td>\n",
       "      <td>2023-12-05</td>\n",
       "      <td>5</td>\n",
       "      <td>Website</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>M</td>\n",
       "      <td>Married</td>\n",
       "      <td>Low</td>\n",
       "      <td>1228</td>\n",
       "      <td>2022-07-24</td>\n",
       "      <td>397.37</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>2022-03-17</td>\n",
       "      <td>Inquiry</td>\n",
       "      <td>Resolved</td>\n",
       "      <td>2023-12-05</td>\n",
       "      <td>5</td>\n",
       "      <td>Website</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6807</th>\n",
       "      <td>1000</td>\n",
       "      <td>34</td>\n",
       "      <td>M</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Low</td>\n",
       "      <td>2724</td>\n",
       "      <td>2022-09-08</td>\n",
       "      <td>232.06</td>\n",
       "      <td>Groceries</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-13</td>\n",
       "      <td>22</td>\n",
       "      <td>Mobile App</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6808</th>\n",
       "      <td>1000</td>\n",
       "      <td>34</td>\n",
       "      <td>M</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Low</td>\n",
       "      <td>2917</td>\n",
       "      <td>2022-12-13</td>\n",
       "      <td>324.98</td>\n",
       "      <td>Books</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-13</td>\n",
       "      <td>22</td>\n",
       "      <td>Mobile App</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6809</th>\n",
       "      <td>1000</td>\n",
       "      <td>34</td>\n",
       "      <td>M</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Low</td>\n",
       "      <td>2979</td>\n",
       "      <td>2022-06-15</td>\n",
       "      <td>375.34</td>\n",
       "      <td>Groceries</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-13</td>\n",
       "      <td>22</td>\n",
       "      <td>Mobile App</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6810</th>\n",
       "      <td>1000</td>\n",
       "      <td>34</td>\n",
       "      <td>M</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Low</td>\n",
       "      <td>8594</td>\n",
       "      <td>2022-04-08</td>\n",
       "      <td>166.73</td>\n",
       "      <td>Books</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-13</td>\n",
       "      <td>22</td>\n",
       "      <td>Mobile App</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6811</th>\n",
       "      <td>1000</td>\n",
       "      <td>34</td>\n",
       "      <td>M</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Low</td>\n",
       "      <td>5529</td>\n",
       "      <td>2022-11-23</td>\n",
       "      <td>93.73</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-13</td>\n",
       "      <td>22</td>\n",
       "      <td>Mobile App</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6812 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CustomerID  Age Gender MaritalStatus IncomeLevel  TransactionID  \\\n",
       "0              1   62      M        Single         Low           7194   \n",
       "1              2   65      M       Married         Low           7250   \n",
       "2              2   65      M       Married         Low           9660   \n",
       "3              2   65      M       Married         Low           2998   \n",
       "4              2   65      M       Married         Low           1228   \n",
       "...          ...  ...    ...           ...         ...            ...   \n",
       "6807        1000   34      M       Widowed         Low           2724   \n",
       "6808        1000   34      M       Widowed         Low           2917   \n",
       "6809        1000   34      M       Widowed         Low           2979   \n",
       "6810        1000   34      M       Widowed         Low           8594   \n",
       "6811        1000   34      M       Widowed         Low           5529   \n",
       "\n",
       "     TransactionDate  AmountSpent ProductCategory  InteractionID  \\\n",
       "0         2022-03-27       416.50     Electronics         6363.0   \n",
       "1         2022-08-08        54.96        Clothing         3329.0   \n",
       "2         2022-07-25       197.50     Electronics         3329.0   \n",
       "3         2022-01-25       101.31       Furniture         3329.0   \n",
       "4         2022-07-24       397.37        Clothing         3329.0   \n",
       "...              ...          ...             ...            ...   \n",
       "6807      2022-09-08       232.06       Groceries            NaN   \n",
       "6808      2022-12-13       324.98           Books            NaN   \n",
       "6809      2022-06-15       375.34       Groceries            NaN   \n",
       "6810      2022-04-08       166.73           Books            NaN   \n",
       "6811      2022-11-23        93.73       Furniture            NaN   \n",
       "\n",
       "     InteractionDate InteractionType ResolutionStatus LastLoginDate  \\\n",
       "0         2022-03-31         Inquiry         Resolved    2023-10-21   \n",
       "1         2022-03-17         Inquiry         Resolved    2023-12-05   \n",
       "2         2022-03-17         Inquiry         Resolved    2023-12-05   \n",
       "3         2022-03-17         Inquiry         Resolved    2023-12-05   \n",
       "4         2022-03-17         Inquiry         Resolved    2023-12-05   \n",
       "...              ...             ...              ...           ...   \n",
       "6807             NaN             NaN              NaN    2023-08-13   \n",
       "6808             NaN             NaN              NaN    2023-08-13   \n",
       "6809             NaN             NaN              NaN    2023-08-13   \n",
       "6810             NaN             NaN              NaN    2023-08-13   \n",
       "6811             NaN             NaN              NaN    2023-08-13   \n",
       "\n",
       "      LoginFrequency ServiceUsage  ChurnStatus  \n",
       "0                 34   Mobile App            0  \n",
       "1                  5      Website            1  \n",
       "2                  5      Website            1  \n",
       "3                  5      Website            1  \n",
       "4                  5      Website            1  \n",
       "...              ...          ...          ...  \n",
       "6807              22   Mobile App            0  \n",
       "6808              22   Mobile App            0  \n",
       "6809              22   Mobile App            0  \n",
       "6810              22   Mobile App            0  \n",
       "6811              22   Mobile App            0  \n",
       "\n",
       "[6812 rows x 17 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3110cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Remove duplicates\n",
    "df1 = df1.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "890e77d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_20128\\3013326947.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df1['AmountSpent'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Handle missing values\n",
    "df1.fillna({'Gender': 'Unknown', 'MaritalStatus': 'Unknown', 'IncomeLevel': 'Unknown'}, inplace=True)\n",
    "df1['AmountSpent'].fillna(0, inplace=True)\n",
    "# Convert dates\n",
    "for date_col in ['TransactionDate', 'InteractionDate', 'LastLoginDate']:\n",
    "    df1[date_col] = pd.to_datetime(df1[date_col], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d99f108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CustomerID', 'Age', 'Gender', 'MaritalStatus', 'IncomeLevel',\n",
      "       'TransactionID', 'TransactionDate', 'AmountSpent', 'ProductCategory',\n",
      "       'InteractionID', 'InteractionDate', 'InteractionType',\n",
      "       'ResolutionStatus', 'LastLoginDate', 'LoginFrequency', 'ServiceUsage',\n",
      "       'ChurnStatus'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9db07368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Encode categoricals\n",
    "df1 = pd.get_dummies(df1, columns=['Gender', 'MaritalStatus', 'IncomeLevel', 'ProductCategory', 'InteractionType', 'ResolutionStatus', 'ServiceUsage'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c53aedd",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Agefirst'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m     16\u001b[0m num_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAgefirst\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoginFrequency mean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAmountSpent sum\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAmountSpent mean\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# etc.\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m labeled_df[num_cols] \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(labeled_df[num_cols])\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4112\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4113\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4115\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6212\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6209\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6210\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6212\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6214\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6216\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6264\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6263\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6264\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Agefirst'] not in index\""
     ]
    }
   ],
   "source": [
    "# Step 5: Aggregate per customer (example)\n",
    "customer_features = df1.groupby('CustomerID').agg({\n",
    "    'Age': 'first',\n",
    "    'LoginFrequency': 'mean',  # example\n",
    "    'AmountSpent': ['sum', 'mean', 'count'],\n",
    "    'TransactionDate': 'max',\n",
    "    # add more aggregations as needed\n",
    "}).reset_index()\n",
    "customer_features.columns = [' '.join(col).strip() for col in customer_features.columns.values]  # Flatten cols\n",
    "\n",
    "# Merge with churn label (assuming it's available in your data)\n",
    "labeled_df = customer_features.merge(df1[['CustomerID', 'ChurnStatus']].drop_duplicates(), on='CustomerID', how='left')\n",
    "\n",
    "# Step 6: Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "num_cols = ['Agefirst', 'LoginFrequency mean', 'AmountSpent sum', 'AmountSpent mean']  # etc.\n",
    "labeled_df[num_cols] = scaler.fit_transform(labeled_df[num_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce8fce72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Save or proceed to modeling\n",
    "labeled_df.to_csv('data_cleaned_processed_for_ml.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e968a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Age first</th>\n",
       "      <th>LoginFrequency mean</th>\n",
       "      <th>AmountSpent sum</th>\n",
       "      <th>AmountSpent mean</th>\n",
       "      <th>AmountSpent count</th>\n",
       "      <th>TransactionDate max</th>\n",
       "      <th>ChurnStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>34.0</td>\n",
       "      <td>416.50</td>\n",
       "      <td>416.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-03-27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1547.42</td>\n",
       "      <td>221.060000</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-11-19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1702.98</td>\n",
       "      <td>283.830000</td>\n",
       "      <td>6</td>\n",
       "      <td>2022-10-08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1834.58</td>\n",
       "      <td>183.458000</td>\n",
       "      <td>10</td>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2001.49</td>\n",
       "      <td>250.186250</td>\n",
       "      <td>8</td>\n",
       "      <td>2022-12-21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>996</td>\n",
       "      <td>54</td>\n",
       "      <td>38.0</td>\n",
       "      <td>227.25</td>\n",
       "      <td>227.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-07-24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>997</td>\n",
       "      <td>19</td>\n",
       "      <td>5.0</td>\n",
       "      <td>419.82</td>\n",
       "      <td>209.910000</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-10-25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>998</td>\n",
       "      <td>47</td>\n",
       "      <td>47.0</td>\n",
       "      <td>252.15</td>\n",
       "      <td>252.150000</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-09-18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>999</td>\n",
       "      <td>23</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2393.26</td>\n",
       "      <td>265.917778</td>\n",
       "      <td>9</td>\n",
       "      <td>2022-12-07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1000</td>\n",
       "      <td>34</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1670.79</td>\n",
       "      <td>278.465000</td>\n",
       "      <td>6</td>\n",
       "      <td>2022-12-13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CustomerID  Age first  LoginFrequency mean  AmountSpent sum  \\\n",
       "0             1         62                 34.0           416.50   \n",
       "1             2         65                  5.0          1547.42   \n",
       "2             3         18                  3.0          1702.98   \n",
       "3             4         21                  2.0          1834.58   \n",
       "4             5         21                 41.0          2001.49   \n",
       "..          ...        ...                  ...              ...   \n",
       "995         996         54                 38.0           227.25   \n",
       "996         997         19                  5.0           419.82   \n",
       "997         998         47                 47.0           252.15   \n",
       "998         999         23                 23.0          2393.26   \n",
       "999        1000         34                 22.0          1670.79   \n",
       "\n",
       "     AmountSpent mean  AmountSpent count TransactionDate max  ChurnStatus  \n",
       "0          416.500000                  1          2022-03-27            0  \n",
       "1          221.060000                  7          2022-11-19            1  \n",
       "2          283.830000                  6          2022-10-08            0  \n",
       "3          183.458000                 10          2022-12-27            0  \n",
       "4          250.186250                  8          2022-12-21            0  \n",
       "..                ...                ...                 ...          ...  \n",
       "995        227.250000                  1          2022-07-24            0  \n",
       "996        209.910000                  2          2022-10-25            0  \n",
       "997        252.150000                  1          2022-09-18            0  \n",
       "998        265.917778                  9          2022-12-07            0  \n",
       "999        278.465000                  6          2022-12-13            0  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2c1b7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 8)\n",
      "   CustomerID  Age first  LoginFrequency mean  AmountSpent sum  \\\n",
      "0           1         62                 34.0           416.50   \n",
      "1           2         65                  5.0          1547.42   \n",
      "2           3         18                  3.0          1702.98   \n",
      "3           4         21                  2.0          1834.58   \n",
      "4           5         21                 41.0          2001.49   \n",
      "\n",
      "   AmountSpent mean  AmountSpent count TransactionDate max  ChurnStatus  \n",
      "0         416.50000                  1          2022-03-27            0  \n",
      "1         221.06000                  7          2022-11-19            1  \n",
      "2         283.83000                  6          2022-10-08            0  \n",
      "3         183.45800                 10          2022-12-27            0  \n",
      "4         250.18625                  8          2022-12-21            0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"data_cleaned_processed_for_ml.csv\")\n",
    "print(df.shape)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7143cfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(\"ChurnStatus\", axis=1)  # replace \"Churn\" with your actual target column\n",
    "y = df[\"ChurnStatus\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d40133",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79398662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86       150\n",
      "           1       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.75       200\n",
      "   macro avg       0.38      0.50      0.43       200\n",
      "weighted avg       0.56      0.75      0.64       200\n",
      "\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86       150\n",
      "           1       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.75       200\n",
      "   macro avg       0.38      0.50      0.43       200\n",
      "weighted avg       0.56      0.75      0.64       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ----- Load data -----\n",
    "df = pd.read_csv(\"data_cleaned_processed_for_ml.csv\")\n",
    "X = df.drop(\"ChurnStatus\", axis=1)   # Change 'target' to your actual target column\n",
    "y = df[\"ChurnStatus\"]\n",
    "\n",
    "# ----- Convert dates to ordinal -----\n",
    "for col in X.columns:\n",
    "    if np.issubdtype(X[col].dtype, np.datetime64):\n",
    "        X[col] = pd.to_datetime(X[col]).map(pd.Timestamp.toordinal)\n",
    "    elif X[col].dtype == object:\n",
    "        try:\n",
    "            X[col] = pd.to_datetime(X[col]).map(pd.Timestamp.toordinal)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# ----- Split train/test -----\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ----- Identify categorical/numeric -----\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns\n",
    "numeric_features = X_train.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "# ----- Preprocessing -----\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "        ('num', 'passthrough', numeric_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ----- Random Forest Random Search -----\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf_param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [None, 5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "rf_search = RandomizedSearchCV(\n",
    "    rf, rf_param_dist, n_iter=20, cv=5, scoring='f1', random_state=42, n_jobs=-1\n",
    ")\n",
    "rf_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', rf_search)])\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# ----- Logistic Regression Random Search -----\n",
    "lr = LogisticRegression(max_iter=1000, solver='liblinear')\n",
    "lr_param_dist = {\n",
    "    'C': np.logspace(-4, 4, 20),\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "lr_search = RandomizedSearchCV(\n",
    "    lr, lr_param_dist, n_iter=20, cv=5, scoring='f1', random_state=42, n_jobs=-1\n",
    ")\n",
    "lr_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', lr_search)])\n",
    "lr_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# ----- Evaluate -----\n",
    "rf_pred = rf_pipeline.predict(X_test)\n",
    "lr_pred = lr_pipeline.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, rf_pred))\n",
    "\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, lr_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "243cfefb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'BayeSearchCV' from 'skopt' (d:\\Anaconda\\Lib\\site-packages\\skopt\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, recall_score, f1_score\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskopt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BayeSearchCV\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskopt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspace\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Real, Integer, Categorical\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'BayeSearchCV' from 'skopt' (d:\\Anaconda\\Lib\\site-packages\\skopt\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from skopt import BayeSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# -------------------\n",
    "# 1. Preprocessing\n",
    "# -------------------\n",
    "\n",
    "# Example: convert date columns to numeric\n",
    "for col in X_train.columns:\n",
    "    if np.issubdtype(X_train[col].dtype, np.datetime64):\n",
    "        X_train[col] = X_train[col].view('int64') // 10**9\n",
    "    elif X_train[col].dtype == 'object':\n",
    "        try:\n",
    "            X_train[col] = pd.to_datetime(X_train[col]).view('int64') // 10**9\n",
    "        except:\n",
    "            le = LabelEncoder()\n",
    "            X_train[col] = le.fit_transform(X_train[col].astype(str))\n",
    "\n",
    "# Repeat for X_test\n",
    "for col in X_test.columns:\n",
    "    if np.issubdtype(X_test[col].dtype, np.datetime64):\n",
    "        X_test[col] = X_test[col].view('int64') // 10**9\n",
    "    elif X_test[col].dtype == 'object':\n",
    "        try:\n",
    "            X_test[col] = pd.to_datetime(X_test[col]).view('int64') // 10**9\n",
    "        except:\n",
    "            le = LabelEncoder()\n",
    "            X_test[col] = le.fit_transform(X_test[col].astype(str))\n",
    "\n",
    "# -------------------\n",
    "# 2. Bayesian Search - Random Forest\n",
    "# -------------------\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_search = BayesSearchCV(\n",
    "    rf,\n",
    "    {\n",
    "        'n_estimators': Integer(100, 300),\n",
    "        'max_depth': Integer(5, 30),\n",
    "        'min_samples_split': Integer(2, 10),\n",
    "        'min_samples_leaf': Integer(1, 5)\n",
    "    },\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_search.fit(X_train, y_train)\n",
    "rf_best = rf_search.best_estimator_\n",
    "\n",
    "# -------------------\n",
    "# 3. Bayesian Search - Logistic Regression\n",
    "# -------------------\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "log_reg_search = BayesSearchCV(\n",
    "    log_reg,\n",
    "    {\n",
    "        'C': Real(1e-3, 10, prior='log-uniform'),\n",
    "        'penalty': Categorical(['l1', 'l2']),\n",
    "        'solver': Categorical(['liblinear', 'saga'])\n",
    "    },\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "log_reg_search.fit(X_train, y_train)\n",
    "log_reg_best = log_reg_search.best_estimator_\n",
    "\n",
    "# -------------------\n",
    "# 4. Evaluation\n",
    "# -------------------\n",
    "models = {\n",
    "    \"Random Forest\": rf_best,\n",
    "    \"Logistic Regression\": log_reg_best\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred),\n",
    "        \"Recall\": recall_score(y_test, y_pred),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred)\n",
    "    })\n",
    "\n",
    "metrics_df = pd.DataFrame(results)\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a35ac90",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 180 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n36 fits failed with the following error:\nTraceback (most recent call last):\n  File \"d:\\Anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"d:\\Anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 345, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 584, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1106, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"d:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 879, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 185, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Anaconda\\Lib\\site-packages\\pandas\\core\\generic.py\", line 2168, in __array__\n    arr = np.asarray(values, dtype=dtype)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: '2022-12-03'\n\n--------------------------------------------------------------------------------\n144 fits failed with the following error:\nTraceback (most recent call last):\n  File \"d:\\Anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"d:\\Anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 345, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 584, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1106, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"d:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 879, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 185, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Anaconda\\Lib\\site-packages\\pandas\\core\\generic.py\", line 2168, in __array__\n    arr = np.asarray(values, dtype=dtype)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: '2022-12-14'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 20\u001b[0m\n\u001b[0;32m      6\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m300\u001b[39m],\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m],\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_samples_split\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m5\u001b[39m],\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_samples_leaf\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     11\u001b[0m }\n\u001b[0;32m     13\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m     14\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mrf,\n\u001b[0;32m     15\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparam_grid,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     19\u001b[0m )\n\u001b[1;32m---> 20\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     22\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:851\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    844\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    845\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    846\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    847\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    848\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    849\u001b[0m     )\n\u001b[1;32m--> 851\u001b[0m _warn_or_raise_about_fit_failures(out, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_score)\n\u001b[0;32m    853\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 180 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n36 fits failed with the following error:\nTraceback (most recent call last):\n  File \"d:\\Anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"d:\\Anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 345, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 584, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1106, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"d:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 879, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 185, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Anaconda\\Lib\\site-packages\\pandas\\core\\generic.py\", line 2168, in __array__\n    arr = np.asarray(values, dtype=dtype)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: '2022-12-03'\n\n--------------------------------------------------------------------------------\n144 fits failed with the following error:\nTraceback (most recent call last):\n  File \"d:\\Anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"d:\\Anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 345, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 584, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1106, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"d:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 879, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 185, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Anaconda\\Lib\\site-packages\\pandas\\core\\generic.py\", line 2168, in __array__\n    arr = np.asarray(values, dtype=dtype)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: '2022-12-14'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [None, 10, 20],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"min_samples_leaf\": [1, 2]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"f1\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36330aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, RocCurveDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_proba))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# ROC Curve\n",
    "RocCurveDisplay.from_estimator(best_model, X_test, y_test)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
